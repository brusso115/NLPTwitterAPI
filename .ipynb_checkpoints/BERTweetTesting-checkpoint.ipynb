{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import shutil\n",
    "import emoji\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c704b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 65\n",
    "def tokenize(sentence):\n",
    "    tokens = tokenizer.encode_plus(sentence, max_length=SEQ_LEN,\n",
    "                                   truncation=True, padding='max_length',\n",
    "                                   add_special_tokens=True, return_attention_mask=True,\n",
    "                                   return_token_type_ids=False, return_tensors='tf')\n",
    "    return tokens['input_ids'], tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('twitter-sentiment-model-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['I love pizza']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d63c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_test_ids = np.zeros((len(test), SEQ_LEN))\n",
    "single_test_mask = np.zeros((len(test), SEQ_LEN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d11331",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(test):\n",
    "    single_test_ids[i, :], single_test_mask[i, :] = tokenize(sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd645fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict([single_test_ids, single_test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "for pred in predictions:\n",
    "    pred_label.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c83a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
